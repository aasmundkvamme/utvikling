{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CD2_client_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m CD2_client_id \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCD2_client_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m CD2_client_secret \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCD2_client_secret\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m CD2_base_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCD2_base_url\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m<frozen os>:714\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CD2_client_id'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import base64\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import io\n",
    "import shutil\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "\n",
    "CD2_client_id = os.environ['CD2_client_id']\n",
    "CD2_client_secret = os.environ['CD2_client_secret']\n",
    "CD2_base_url = os.environ['CD2_base_url']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def les_access_token(logger):\n",
    "    # Hent access_token\n",
    "    requesturl = \"https://api-gateway.instructure.com/ids/auth/login\"\n",
    "    payload = {'grant_type': 'client_credentials'}\n",
    "    r = requests.request(\n",
    "        \"POST\",\n",
    "        requesturl,\n",
    "        data=payload,\n",
    "        auth=(CD2_client_id, CD2_client_secret)\n",
    "    )\n",
    "    if r.status_code == 200:\n",
    "        respons = r.json()\n",
    "        access_token = respons['access_token']\n",
    "        logger.info(f\"Henta access_token OK: {access_token}\")\n",
    "        return access_token\n",
    "    else:\n",
    "        logger.error(f\"Klarte ikkje å skaffe access_token, feil {r.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_logger(log_namn):\n",
    "    # opprett ein logger\n",
    "    logger = logging.getLogger('my_logger')\n",
    "    logger.setLevel(logging.DEBUG)  # Sett ønska loggnivå\n",
    "\n",
    "    # Opprett formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    # Opprett filhandler for å logge til fil (ein loggfil kvar dag)\n",
    "    file_handler = logging.FileHandler(log_namn)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # Opprett konsollhandler for å logge til konsollen\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.DEBUG)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Legg til handlerne i loggeren\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hent_CD2_filar(innfil, token, svar, logger):\n",
    "    try:\n",
    "        requesturl = f\"{CD2_base_url}/dap/object/url\"\n",
    "        payload = f\"{svar['objects']}\"\n",
    "        payload = payload.replace('\\'', '\\\"')\n",
    "        headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "        logger.info(f\"Request: {requesturl} {payload}\")\n",
    "        respons = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        logger.info(f\"Response: {respons.status_code} {respons.reason}\")\n",
    "        respons.raise_for_status()\n",
    "        fil = respons.json()\n",
    "        logger.info(f\"Objects: {fil}\")\n",
    "        url = fil['urls'][innfil]['url']\n",
    "        logger.info(f\"URL: {url}\")\n",
    "        data = requests.request(\"GET\", url)\n",
    "        logger.info(f\"Response: {data.status_code} {data.reason}\")\n",
    "        buffer = io.BytesIO(data.content)\n",
    "        logger.info(f\"Buffer: {buffer}\")\n",
    "        with gzip.GzipFile(fileobj=buffer, mode='rb') as utpakka_fil:\n",
    "            utpakka_data = utpakka_fil.read().decode(\"utf-8\", errors='ignore')\n",
    "            # logger.info(f\"Data: {utpakka_data}\")\n",
    "        return utpakka_data\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def les_CD2_tabell(token, tabell, logger):\n",
    "    headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "    # sist_oppdatert = akv_finn_sist_oppdatert(tabell)\n",
    "    payload = '{\"format\": \"csv\"}' # % (sist_oppdatert)\n",
    "    requesturl = f\"{CD2_base_url}/dap/query/canvas/table/{tabell}/data\"\n",
    "    print(f\"Sender søk til {requesturl}\")\n",
    "    try:\n",
    "        r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        r.raise_for_status()\n",
    "        respons = r.json()\n",
    "        id = respons['id']\n",
    "        vent = True\n",
    "        while vent:\n",
    "            requesturl2 = f\"{CD2_base_url}/dap//job/{id}\"\n",
    "            r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "            time.sleep(5)\n",
    "            respons2 = r2.json()\n",
    "            print(respons2)\n",
    "            if respons2['status'] == \"complete\":\n",
    "                vent = False\n",
    "                filar = respons2['objects']\n",
    "        dr_liste = []\n",
    "        print(filar)\n",
    "        for fil in filar:\n",
    "            data = io.StringIO(akv_hent_CD2_filar(fil['id'], token, respons2))\n",
    "            df = pd.read_csv(data, sep=\",\")\n",
    "            dr_liste.append(df)\n",
    "        alledata = pd.concat(df for df in dr_liste if not df.empty)\n",
    "        return alledata, sist_oppdatert, respons2['until']\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def akv_finn_sist_oppdatert(tabell):\n",
    "    \"\"\"\n",
    "    Return the latest update time for the given table from the akv_sist_oppdatert table.\n",
    "    \"\"\"\n",
    "    conn_str = os.environ[\"Connection_SQL\"] \n",
    "    try:\n",
    "        with pyodbc.connect(conn_str) as connection:\n",
    "            cursor = connection.cursor()\n",
    "            print(connection)\n",
    "            query = \"\"\"\n",
    "            SELECT [sist_oppdatert] FROM [dbo].[akv_sist_oppdatert]\n",
    "            WHERE [tabell] = ?\n",
    "            \"\"\"\n",
    "            cursor.execute(query, (tabell,))\n",
    "            row = cursor.fetchone()\n",
    "            print(row)\n",
    "            if row:\n",
    "                print(\"Har henta frå Azure\")\n",
    "                if tabell == \"web_logs\":\n",
    "                    return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "                else:\n",
    "                    return row[0].isoformat() + \"Z\"\n",
    "            else:\n",
    "                print(\"Har ikkje henta frå Azure\")\n",
    "                if tabell == \"web_logs\":\n",
    "                    return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "                else:\n",
    "                    return (date.today() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "    except pyodbc.Error as exc:\n",
    "        print(\"Har ikkje henta frå Azure\")\n",
    "        if tabell == \"web_logs\":\n",
    "            return (datetime.now() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "        else:\n",
    "            return (datetime.today() - timedelta(days=1)).isoformat() + \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 10:37:48,883 - my_logger - INFO - Henta access_token OK: eyJhbGciOiJSUzI1NiIsImtpZCI6InB1YmxpYzpoeWRyYS5qd3QuYWNjZXNzLXRva2VuIiwidHlwIjoiSldUIn0.eyJhdWQiOltdLCJjbGllbnRfaWQiOiJldS13ZXN0LTEjMTUwNWNjNGUtZjlhYS00MWQ1LWEzNjQtMjE0Njk5ZWJlNjZiIiwiZXhwIjoxNzUwMjM5NDY4LCJleHQiOnt9LCJpYXQiOjE3NTAyMzU4NjgsImlzcyI6Imh0dHBzOi8vaXNzLWV1LXdlc3QtMS5pZGVudGl0eS5pbnN0cnVjdHVyZS5jb20vIiwianRpIjoiMTlkMjg0YzMtNzYwMi00YTlmLWJkOGItMzQxZWRmZWFiMjQwIiwibmJmIjoxNzUwMjM1ODY4LCJzY3AiOlsiZGFwIiwicGFydG5lcjpJTlNUSVRVVElPTkFMX1BBUlRORVIiLCJyZWdpb246ZXUtd2VzdC0xIiwicHJpbmNpcGFsOktqWVhGbFd5cUlQMzA2ak1Mck94T0U2UVNVMVM4b0Y1bTV0ZmJYeWQiXSwic3ViIjoiZXUtd2VzdC0xIzE1MDVjYzRlLWY5YWEtNDFkNS1hMzY0LTIxNDY5OWViZTY2YiJ9.V6CxaSVmdF7vGOAJph8URVy_4O3KDlovJOOfDoUulPp2d_5LG_dMWLELViWj2XRnPQ6AjCSo_40IMcMg7Uq9SXSkK80pu_nIpiSbbwF_GgEjF5eNuxpubeqYBFzSXNkFXMssPhdom5GgX5a1B7ActVsHPUSEJ4xb5I3-7w98oHTyTraIcPDyQxHSH4dO8dkMFk3Tsqdf9ctAN0Yj_hmVPZf8b5RdUsOu_A7FuuuNd6mgu9S6QGs97Rlq0HBJvLBg2Mjw_WHRTsHhyvIlb-YWCAifLnMlFgSkZVTzgoqeJIhtL3or5NmvYJX5E2izt8qWzt0r98lFyEPidIND_kTjbxKG4KOrB-iOrgKkWKJf4tj7Vaiu_S_kzSzQ_EYSaGG1GTN5nroMfvabbTfoXargdxwOrSa3nJ_EiDG6jNlyEzWNUdKY6yVGSeiJ5W9W3Zz8N0KcfoE1jNUghcNS1sv2OGmgajzQ47IkIPevgk8VlO6u_QXMfhdznkM-luCW9j_GnBVTwiV1Amf6RzVItpK1Y0bTtHg4HM5-Pn3ZmrP1rDoQ5DyOCyodA2hSWLwV56CCEC3is3UIqrTKPOBVs7CFjiuS1itJLo02U8OiVV_kaHbuc0B6xIItPSZq8e3jdLWxP_V017hGayujcPk_h5ig5reEFfRT7UaqO69c9-HYBRk\n",
      "2025-06-18 10:37:48,883 - my_logger - INFO - Henta access_token OK: eyJhbGciOiJSUzI1NiIsImtpZCI6InB1YmxpYzpoeWRyYS5qd3QuYWNjZXNzLXRva2VuIiwidHlwIjoiSldUIn0.eyJhdWQiOltdLCJjbGllbnRfaWQiOiJldS13ZXN0LTEjMTUwNWNjNGUtZjlhYS00MWQ1LWEzNjQtMjE0Njk5ZWJlNjZiIiwiZXhwIjoxNzUwMjM5NDY4LCJleHQiOnt9LCJpYXQiOjE3NTAyMzU4NjgsImlzcyI6Imh0dHBzOi8vaXNzLWV1LXdlc3QtMS5pZGVudGl0eS5pbnN0cnVjdHVyZS5jb20vIiwianRpIjoiMTlkMjg0YzMtNzYwMi00YTlmLWJkOGItMzQxZWRmZWFiMjQwIiwibmJmIjoxNzUwMjM1ODY4LCJzY3AiOlsiZGFwIiwicGFydG5lcjpJTlNUSVRVVElPTkFMX1BBUlRORVIiLCJyZWdpb246ZXUtd2VzdC0xIiwicHJpbmNpcGFsOktqWVhGbFd5cUlQMzA2ak1Mck94T0U2UVNVMVM4b0Y1bTV0ZmJYeWQiXSwic3ViIjoiZXUtd2VzdC0xIzE1MDVjYzRlLWY5YWEtNDFkNS1hMzY0LTIxNDY5OWViZTY2YiJ9.V6CxaSVmdF7vGOAJph8URVy_4O3KDlovJOOfDoUulPp2d_5LG_dMWLELViWj2XRnPQ6AjCSo_40IMcMg7Uq9SXSkK80pu_nIpiSbbwF_GgEjF5eNuxpubeqYBFzSXNkFXMssPhdom5GgX5a1B7ActVsHPUSEJ4xb5I3-7w98oHTyTraIcPDyQxHSH4dO8dkMFk3Tsqdf9ctAN0Yj_hmVPZf8b5RdUsOu_A7FuuuNd6mgu9S6QGs97Rlq0HBJvLBg2Mjw_WHRTsHhyvIlb-YWCAifLnMlFgSkZVTzgoqeJIhtL3or5NmvYJX5E2izt8qWzt0r98lFyEPidIND_kTjbxKG4KOrB-iOrgKkWKJf4tj7Vaiu_S_kzSzQ_EYSaGG1GTN5nroMfvabbTfoXargdxwOrSa3nJ_EiDG6jNlyEzWNUdKY6yVGSeiJ5W9W3Zz8N0KcfoE1jNUghcNS1sv2OGmgajzQ47IkIPevgk8VlO6u_QXMfhdznkM-luCW9j_GnBVTwiV1Amf6RzVItpK1Y0bTtHg4HM5-Pn3ZmrP1rDoQ5DyOCyodA2hSWLwV56CCEC3is3UIqrTKPOBVs7CFjiuS1itJLo02U8OiVV_kaHbuc0B6xIItPSZq8e3jdLWxP_V017hGayujcPk_h5ig5reEFfRT7UaqO69c9-HYBRk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Har ikkje henta frå Azure\n"
     ]
    }
   ],
   "source": [
    "tabell = \"courses\"\n",
    "logger = lag_logger(f'loggfil-{tabell}.log')\n",
    "token = les_access_token(logger)\n",
    "# data = les_CD2_tabell(token, tabell, logger)\n",
    "headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "sist_oppdatert = akv_finn_sist_oppdatert(tabell)\n",
    "sist_oppdatert = \"2025-01-01T01:00:00Z\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender søk til https://api-gateway.instructure.com/dap/query/canvas/table/courses/data\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://api-gateway.instructure.com/dap/query/canvas/table/courses/data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, requesturl, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m respons \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m respons[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-gateway.instructure.com/dap/query/canvas/table/courses/data"
     ]
    }
   ],
   "source": [
    "payload = '{\"format\": \"csv\", \"since\": \\\"%s\\\"}' % (sist_oppdatert)\n",
    "requesturl = f\"{CD2_base_url}/dap/query/canvas/table/{tabell}/data\"\n",
    "print(f\"Sender søk til {requesturl}\")\n",
    "# try:\n",
    "r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "r.raise_for_status()\n",
    "respons = r.json()\n",
    "id = respons['id']\n",
    "vent = True\n",
    "while vent:\n",
    "    requesturl2 = f\"{CD2_base_url}/dap//job/{id}\"\n",
    "    r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "    time.sleep(5)\n",
    "    respons2 = r2.json()\n",
    "    print(respons2)\n",
    "    if respons2['status'] == \"complete\":\n",
    "        vent = False\n",
    "        filar = respons2['objects']\n",
    "dr_liste = []\n",
    "print(filar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fil in filar:\n",
    "    logger.info(f\"Henter fil {fil['id']}\")\n",
    "    data = io.StringIO(hent_CD2_filar(fil['id'], token, respons2, logger))\n",
    "    df = pd.read_csv(data, sep=\",\")\n",
    "    dr_liste.append(df)\n",
    "alledata = pd.concat(df for df in dr_liste if not df.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lagre data til fil\n",
    "Den følgjande koden vil bli endra frå gang til gang; den bruker eg for å ta ut dei data som er interessante i kvart tilfelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alledata[['key.id', 'value.enrollment_term_id', ]].to_csv(\"courses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
